---
title: "Analysis master thesis"
author: "Jaskaran Singh Gill"
date: "2024-02-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Importing the data_stats

```{r}
library(ggplot2)
data_table_sel = read.csv("Documents/Master_thesis_meta/Master_thesis/thesis_project_jaskaran/workflow/combined_meta_file_sel.csv",header = TRUE)
data_table_bottleneck = read.csv("Documents/Master_thesis_meta/Master_thesis/thesis_project_jaskaran/workflow/combined_meta_file_bottleneck.csv",header = TRUE)

data_table_sel$category = 0
data_table_bottleneck$category = 1
data_table_sel <- data_table_sel[c(-1)]
data_table_bottleneck <- data_table_bottleneck[c(-1)]

data_table_combined <- rbind(data_table_sel,data_table_bottleneck)

m <- colnames(data_table_combined)
m
```

```{r}
data_table_sel
data_table_bottleneck
data_table_combined
```

```{r}
install.packages("e1071")
library(e1071)

model_svm  <- svm(selection_coefficient_category ~ average_h + category_sfs_1 + category_sfs_2 + category_sfs_3  + category_sfs_5 + category_sfs_6 + category_sfs_7 + category_sfs_8 , data = data_table, kernel = "sigmoid",gamma = 1)
```

```{r}
set.seed(123)
train_indices <- sample(1:nrow(data_table_combined), 0.8 * nrow(data_table_combined))
train_data <- data_table_combined[train_indices, ]
test_data <- data_table_combined[-train_indices, ]
```

```{r}
# Load necessary libraries
library(e1071)

# Split data into training and testing sets (e.g., 80-20 split)
set.seed(123)
data_table_combined <- drop_na(data_table_combined)
data_table_combined_svm <- data_table_combined[c(-1,-5,-6,-7,-8,-9)]
train_indices <- sample(1:nrow(data_table_combined), 0.8 * nrow(data_table_combined))
train_data <- data_table_combined_svm[train_indices, ]
test_data <- data_table_combined_svm[-train_indices, ]
train_data
# Convert the target variable to a factor
train_data$category <- as.factor(train_data$category)
test_data$category <- as.factor(test_data$category)

# Train SVM model
train_data <- drop_na(train_data)
model <- svm(category ~ ., data = train_data, kernel = "radial")

# Evaluate model
test_data <- drop_na(test_data)
predicted <- predict(model, newdata = test_data)

length(predicted)
accuracy <- mean(predicted == test_data$category)
accuracy * 100


confusion_matrix <- table(predicted, test_data$category)
confusion_matrix

# Calculate precision
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
precision

# Calculate recall (sensitivity)
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
recall

# Calculate F1 score
f1_score <- 2 * precision * recall / (precision + recall)
f1_score


```
```{r}
# Load necessary libraries
library(pROC)
library(ggplot2)
library(e1071)  # Adding e1071 library for SVM

# Train SVM model
set.seed(123)

data_table_combined <- drop_na(data_table_combined)
data_table_combined
data_table_combined_svm <- data_table_combined[c(-5,-6,-7,-8,-9)]
train_indices <- sample(1:nrow(data_table_combined), 7846)
train_data <- data_table_combined_svm[train_indices, ]
test_data <- data_table_combined_svm[-train_indices, ]
length(train_indices)
# Convert the target variable to a factor
train_data$category <- as.factor(train_data$category)
test_data$category <- as.factor(test_data$category)

# Train SVM model
train_data <- drop_na(train_data)
model <- svm(category ~ Tajimas_D + Tajima_pi + num_of_mutation + average_h + category_sfs_1 + category_sfs_2 + category_sfs_3 + category_sfs_4 + category_sfs_5 + category_sfs_6 + category_sfs_7 + category_sfs_8+ category_sfs_9, data = train_data, kernel = "radial", probability = TRUE)


# Evaluate model
test_data <- drop_na(test_data)
predicted <- predict(model, newdata = test_data, probability = TRUE)

confusion_matrix <- table(Actual = test_data$category, Predicted = predicted)

# Get predicted probabilities
predicted_prob <- attr(predicted, "probabilities")[, 2]

# Generate ROC curve
roc_curve <- roc(as.numeric(test_data$category) - 1, predicted_prob)

# Convert ROC curve data to data frame
roc_df <- data.frame(
  FPR = 1-roc_curve$specificities,
  TPR = roc_curve$sensitivities
)

label_x <- 0.05
label_y <- 0.8

# Plot ROC curve using ggplot2
ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_line(color = "black") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(x = "False Positive Rate", y = "True Positive Rate", title = "ROC Curve") + 
  theme(text= element_text(family = "Optima"))


correctly_classified_indices <- which(test_data$category == predicted)
correctly_classified_df <- test_data[correctly_classified_indices,]
correctly_classified_sel <- correctly_classified_df[correctly_classified_df$category==0,]
correctly_classified_sel$selection_coefficient <- sub(".*/selection_(\\d+\\.\\d+)\\.fasta", "\\1", correctly_classified_sel$fasta_file)
correctly_classified_bottleneck <- correctly_classified_df[correctly_classified_df$category==1,]
correctly_classified_bottleneck$bottleneck_intensity <- as.numeric(sub(".*/(selection|bottleneck)_(\\d+\\.\\d+)\\.fasta", "\\2", correctly_classified_bottleneck$fasta_file))

misclassified_indices <- which(test_data$category != predicted)
misclassified_df <- test_data[misclassified_indices,]

misclassified_sel <- misclassified_df[misclassified_df$category==0,]
misclassified_bottleneck <- misclassified_df[misclassified_df$category==1,]
misclassified_sel$selection_coefficient <- sub(".*/selection_(\\d+\\.\\d+)\\.fasta", "\\1", misclassified_sel$fasta_file)
misclassified_sel <- drop_na(misclassified_sel)
mean(as.numeric(misclassified_sel$selection_coefficient))
as.numeric(misclassified_sel$selection_coefficient)
misclassified_bottleneck$bottleneck_intensity <- sub(".*/(selection|bottleneck)_(\\d+\\.\\d+)\\.fasta", "\\2", misclassified_bottleneck$fasta_file)
misclassified_bottleneck$bottleneck_intensity <- as.numeric(misclassified_bottleneck$bottleneck_intensity)

misclassified_bottleneck$bottleneck_intensity

mean(misclassified_bottleneck$bottleneck_intensity)
sd(misclassified_bottleneck$bottleneck_intensity)

mean(correctly_classified_bottleneck$bottleneck_intensity)

wilcox.test(misclassified_bottleneck$bottleneck_intensity, correctly_classified_bottleneck$bottleneck_intensity, alternative = c("greater"))

misclassified_sel$selection_coefficient <- as.numeric(misclassified_sel$selection_coefficient)
correctly_classified_sel$selection_coefficient <- as.numeric(correctly_classified_sel$selection_coefficient)
mean(misclassified_sel$selection_coefficient )
sd(misclassified_sel$selection_coefficient)

wilcox.test(misclassified_sel$selection_coefficient, correctly_classified_sel$selection_coefficient, alternative = c("less"))

confusion_matrix
model

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)
accuracy
precision
recall
f1_score
confusion_matrix
misclassified_bottleneck
misclassified_sel 


```




```{r}
library(caret)
library(e1071)
library(ggplot2)

# Assuming your data frame containing PC1 and PC2 is named 'pcs'

# Step 1: Split data into training and testing sets
set.seed(123)  # For reproducibility
9830-7846
train_indices <- sample(1:nrow(data_table_combined), 7846)
train_data <- pcs[-train_indices, ]
test_data <- pcs[-train_indices, ]

# Step 2: Train the SVM classifier
svm_model <- svm(category ~ PC1 + PC2, data = train_data, kernel = "radial")

# Step 3: Predict class labels for test data
predictions <- predict(svm_model, newdata = test_data[, c("PC1", "PC2")])

# Step 4: Assess the performance of the classifier
confusion_matrix <- table(Actual = test_data$category, Predicted = predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)

misclassified_indices <- which(test_data$category != predictions)

# View confusion matrix and performance metrics
print(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")

x1 <- seq(min(pcs$PC1) - 1, max(pcs$PC1) + 1, length.out = 1000)
x2 <- seq(min(pcs$PC2) - 1, max(pcs$PC2) + 1, length.out = 1000)
grid <- expand.grid(PC1 = x1, PC2 = x2)

predictions <- predict(svm_model, newdata = grid)

# Check the structure of predictions
str(predictions)
grid$predicted <- as.numeric(as.character(predictions))
# Assuming you have the coordinates of support vectors stored in svm_model object
support_vectors <- data.frame(PC1 = svm_model$SV[,1], PC2 = svm_model$SV[,2])
# Plot decision boundary
ggplot() +
  geom_point(data = train_data, aes(x = PC1, y = PC2, color = as.factor(category)), alpha = 0.4) +
  geom_contour(data = grid, aes(x = PC1, y = PC2, z = predicted), bins = 20, color = "black") +
  geom_point(data = support_vectors, aes(x = PC1, y = PC2), color = "gold", size = 2, shape = 20) + # Add support vectors
  labs(x = "PC1", y = "PC2", color = "Evolutionary Scenario") +
  scale_color_manual(values = c("blue", "red", "gold"), labels = c("Selection", "Bottleneck", "Support Vector")) +
  theme(text = element_text(family = "Monaco")) +
  guides(color = guide_legend(title = "Evolutionary Scenario",
                              labels = c("Selection", "Bottleneck", "Support Vector")))

ggplot() +
  geom_point(data = train_data, aes(x = PC1, y = PC2, color = as.factor(category)), alpha = 0.4) +
  geom_contour(data = grid, aes(x = PC1, y = PC2, z = predicted), bins = 20, color = "black") +
  geom_point(data = support_vectors, aes(x = PC1, y = PC2), color = "gold", size = 2, shape = 20) + # Add support vectors
  labs(x = "PC1", y = "PC2", color = "Evolutionary Scenario") +
  scale_color_manual(values = c("blue", "red", "gold"), 
                     labels = c("Selection", "Bottleneck", "Support Vector")) +
  theme(text = element_text(family = "Monaco", face = "bold")) +
  guides(color = guide_legend(title = "Evolutionary Scenario",
                              labels = c("Selection", "Bottleneck", "Support Vector")))

data_table_combined
confusion_matrix
```
```{r}
colnames(confusion_matrix) <- rownames(confusion_matrix) <- c("Selection", "Bottleneck")

# Convert the matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(confusion_matrix))
names(conf_df) <- c("Actual", "Predicted", "Count")

# Plot the confusion matrix
ggplot(conf_df, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = Count), color ="white") +
  geom_text(aes(label = Count),color = "black") +
  scale_fill_gradient(low = "lightsalmon", high = "yellowgreen") +
  labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5,face = "bold"))+
  theme(axis.text = element_text(size = 10), 
        axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        text = element_text(family = "Monaco"))
```

```{r}
# Load necessary library
library(stats)

data_table_combined1 <- data_table_combined[c(-1,-5,-6,-7,-8,-9)]
data_table_combined1
data_table_combined1 <- drop_na(data_table_combined1)
# Assuming your_data is your dataset (with features as columns)
# Extract features (columns) from your data
features <- data_table_combined1[, -which(names(data_table_combined1) == "category")]
# Standardize the features (optional but recommended)
scaled_features <- scale(features)
# Perform PCA
pca_result <- prcomp(scaled_features, center = TRUE, scale. = TRUE)

# Summarize the results
summary(pca_result)

# Visualize the results (e.g., scree plot)
plot(pca_result, type = "l")

# Extract the principal components (PCs)
pcs <- pca_result$x

# Load necessary libraries
library(ggplot2)

# Assuming pca_result and your_data are available from previous steps

# Extract the principal components
pcs <- as.data.frame(pca_result$x)

# Add the category variable to the principal components data frame
pcs$category <- as.factor(data_table_combined1$category)

# Plot PCA results with categories as colors
library(ggplot2)

ggplot(pcs, aes(x = PC1, y = PC2, color = category)) +
  geom_point(alpha = 0.4) +
  labs(x = "Principal Component 1 (63.72 %)", y = "Principal Component 2 (9.497 %)", color = "Evolutionary Scenario",face="bold") +
  scale_color_discrete(labels = c("Selection","Bottleneck")) +
  theme(text = element_text(family = "Monaco"),
        axis.text = element_text(size = 10,face = "bold"), # Adjust the size of axis labels
        legend.text = element_text(size = 10,face = "bold")) # Adjust the size of legend title and labels
  

```
```{r}
variance <- summary(pca_result)$importance[2, ]
variance
# Create a data frame for plotting
variance_df <- data.frame(PC = 1:length(variance), Variance = variance)
variance_df$cumulative_explained_variance <- cumsum(variance_df$Variance)
# Plot variance across PCs
ggplot(variance_df, aes(x = PC, y = Variance)) +
  geom_line(color= "black") +
  geom_bar(stat = "identity", fill = "yellowgreen", width = 0.5, alpha =0.7)+
  geom_point(color = "grey45")+
  geom_line(aes(x = PC ,y = cumulative_explained_variance) ,color = "orange", linetype=2, size = 1)+
  labs(x = "Principal Component", y = "Proportion of Variance Explained")+
  theme(text = element_text(family = "Monaco"))

ggplot(variance_df, aes(x = PC, y = Variance)) +
  geom_line(color= "black") +
  geom_bar(stat = "identity", fill = "yellowgreen", width = 0.5, alpha =0.7)+
  geom_point(color = "grey45")+
  geom_line(aes(x = PC ,y = cumulative_explained_variance) ,color = "orange", linetype=2, size = 1)+
  labs(x = "Principal Component", y = "Proportion of Variance Explained")+
  theme(text = element_text(family = "Monaco"))+
  scale_y_continuous(sec.axis = sec_axis(~., name = "Cumulative Explained Variance Ratio"))+
  scale_fill_manual(values = c("Variance" = "yellowgreen"), labels = c("Variance")) +
  scale_color_manual(values = c("Cumulative Explained Variance" = "orange"), labels = c("Cumulative Explained Variance Ratio")) +
  guides(fill = guide_legend(title = "Legend Title"), color = guide_legend(title = NULL))


ggplot(variance_df, aes(x = PC, y = Variance, fill = "Variance")) +
  geom_line(aes(x = PC , y = Variance, color= "Variance")) +
  geom_bar(stat = "identity", aes(fill = "Variance"), width = 0.5, alpha = 0.7)+
  geom_point(color = "grey45")+
  geom_line(aes(x = PC ,y = cumulative_explained_variance, color = "Cumulative Explained Variance"), linetype=2, size = 1)+
  labs(x = "Principal Component", y = "Proportion of Variance Explained") +
  theme(text = element_text(family = "Monaco")) +
  scale_color_manual(values = c("Cumulative Explained Variance" = "orange", "Variance" = "black"), labels = c("Cumulative Explained Variance", "Variance"))+
  scale_fill_manual(values = c("Variance" = "yellowgreen"))
```

```{r}
data_table_sel <- drop_na(data_table_sel)
data_table_sel
data_table_sel_pca <- data_table_sel[c(-1,-2,-6,-8,-7,-9,-10)]
data_table_sel_pca 

pca_sel <- prcomp(data_table_sel_pca,center = TRUE, scale. = TRUE)

summary(pca_sel)

# Visualize the results (e.g., scree plot)
plot(pca_sel, type = "l")

# Extract the principal components (PCs)
pcs <- pca_sel$x

# Load necessary libraries
library(ggplot2)

# Assuming pca_result and your_data are available from previous steps

# Extract the principal components
pcs <- as.data.frame(pca_sel$x)

# Add the category variable to the principal components data frame
pcs$selection_coefficient <- data_table_sel$selection_coefficient
# Plot PCA results with categories as colors
ggplot(pcs, aes(x = PC1, y = PC2, color = selection_coefficient)) +
  geom_point() +
  labs(x = "Principal Component 1", y = "Principal Component 2", color = "Selection Coefficient") 
```

```{r}
data_table_bottleneck
data_table_combined
data_table_sel
```

```{r}
library(ggplot2)
data_table_sel = read.csv("Documents/Master_thesis_meta/Master_thesis/thesis_project_jaskaran/workflow/combined_meta_file_sel.csv",header = TRUE)
data_table_bottleneck = read.csv("Documents/Master_thesis_meta/Master_thesis/thesis_project_jaskaran/workflow/combined_meta_file_bottleneck.csv",header = TRUE)


bottleneck_density <- ggplot(data_table_bottleneck, aes(x = bottleneck_intensity))+
                      geom_density(color = "black")+
                      xlab("Bottleneck Intensity")+
                      ylab("Density")
ggsave("Documents/Master_thesis_Meta/bottleneck_density.jpeg", plot = bottleneck_density, device = "jpeg")
```

```{r}
data_table_combined1$category <- as.factor(data_table_combined1$category)
density_plot <- ggplot(data_table_combined1, aes(x = average_h, fill = category)) +
  geom_density(alpha=0.8) + # Overlay densities
  labs(title = "Density Plot of Average haplotype length", x = "Average Haplotype Length", y = "Density", fill = "Scenario") +
  scale_fill_manual(labels = c("0" = "Selection", "1" = "Bottleneck"),values = c("0" ="lightpink", "1" = "turquoise3")) + 
  theme(text = element_text(family ="Monaco"))

density_plot

#ggsave("average_haplotype_length.png",plot=density_plot)
```

```{r}
install.packages("gridExtra")
library("gridExtra")
library("tidyverse")
plots <- list()

data_table_combined1 <- drop_na(data_table_combined1)
# Loop through each parameter and create density plot
for (param in names(data_table_combined1)[-length(data)]) {
  plot <- ggplot(data_table_combined1, aes(x = !!sym(param), fill = category)) +
    geom_density(alpha = 0.5) +
    labs(title = paste("Density Plot of", param), x = param, y = "Density") +
    theme_minimal()
  
  plots[[param]] <- plot
}

# Arrange plots in a grid
grid.arrange(grobs = plots, ncol = 2)
data_table_combined1
```

```{r}
plot(data_table_combined1)

data_table_combined1 %>% group_by(category) %>% summarize(mean = mean(Tajimas_D))
```

```{r}
data_table_sel <- drop_na(data_table_sel)
summary(data_table_sel)
standard_deviation <- apply(data_table_sel , MARGIN = 2, sd)
standard_deviation
```
```{r}
data_table_bottleneck <- drop_na(data_table_bottleneck)
data_table_sel <- drop_na(data_table_sel)
wilcox.test(x= data_table_sel$category_sfs_1 ,y =data_table_bottleneck$category_sfs_1,alternative = c("greater"))
```
```{r}

# Create the bar plot
# Load the ggplot2 library
library(ggplot2)

# Create a data frame with the SFS categories and values
data <- data.frame(
  SFS_Category = c("SFS category 1", "SFS category 2", "SFS category 3", 
                   "SFS category 4", "SFS category 5", "SFS category 6", 
                   "SFS category 7", "SFS category 8", "SFS category 9"),
  Value = c(0.09019, 0.056633, 0.076544, 0.07656, 0.05532, 0.1225, 0.1817, 0.07001, 0.07119)
)

# Create the bar plot with smooth line
ggplot(data, aes(x = SFS_Category, y = Value)) +
  geom_bar(stat = "identity", fill = "darkolivegreen3", width = 0.8) + # Adjust bar width
  geom_smooth(method = "loess", color = "turquoise4", se = FALSE) + # Add smooth line
  geom_point(color = "black") + # Add points
  labs(x = "SFS Category", y = "Mean Proportion across Simulations") +
  ggtitle("Mean of SFS across categories in Bottleneck Scenario") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(family = "Monaco")) # Change major gridline style

```
```{r}
library(ggplot2)

# Create a data frame with the SFS categories and updated values
data <- data.frame(
  SFS_Category = c("SFS category 1", "SFS category 2", "SFS category 3", 
                   "SFS category 4", "SFS category 5", "SFS category 6", 
                   "SFS category 7", "SFS category 8", "SFS category 9"),
  Value = c(0.17964, 0.08795, 0.07917, 0.036688, 0.008596, 0.003210, 0.000000, 0.000000, 0.08520)
)
ggplot(data, aes(x = SFS_Category, y = Value)) +
  geom_bar(stat = "identity", fill = "darkolivegreen3", width = 0.8) + # Adjust bar width
  geom_smooth(method = "loess", color = "turquoise4", se = FALSE) + # Add smooth line
  geom_point(color = "black") + # Add points
  labs(x = "SFS Category", y = "Mean Proportion across Simulations") +
  ggtitle("Mean of SFS across categories in Selection Scenario") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        , text = element_text(family = "Monaco"))
```
```{r}
library(ggplot2)

# Data
epochs <- 1:17
loss <- c(0.69, 0.68, 0.53, 0.28, 0.32, 0.09, 0.13, 0.12, 0.05, 0.25, 0.07, 0.21, 0.11, 0.06, 0.05, 0.11, 0.03)
accuracy <- c(51.81, 56.70, 71.67, 85.03, 85.53, 93.70, 90.32, 93.35, 93.85, 94.66, 94.46, 94.71, 94.10, 92.54, 93.90, 94.10, 93.60)

# Create data frame
progress_df <- data.frame(Epoch = epochs, Loss = loss, Accuracy = accuracy)

# Transform loss to logarithmic scale
progress_df$log_Loss <- log(progress_df$Loss)

progress_df$log_accuracy <- log(progress_df$Accuracy)

ggplot(progress_df, aes(x = Epoch)) +
  geom_line(aes(y = Loss, color = "Loss")) +
  geom_line(aes(y = Accuracy * 100, color = "Accuracy")) +
  scale_y_continuous(
    name = "Loss",
    breaks = seq(0, 0.7, by = 0.1),  # Specify the breaks for the loss axis
    labels = c("0", "0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7")  # Specify the labels for the loss axis
  ) +
  scale_y_continuous(
    name = "Accuracy", 
    sec.axis = sec_axis(~./100, name = "Accuracy")
  ) +
  labs(title = "Training Progress", x = "Epoch") +
  scale_color_manual(values = c("Loss" = "blue", "Accuracy" = "red")) +
  theme_minimal()
```
```{r}
# Load required libraries
library(stats)
library(stats4)
library(matrixStats)
library(FNN)
library(R.utils)
features <- drop_na(features)
pca_result <- prcomp(features, center = TRUE, scale. = TRUE)
eigenvalues <- pca_result$sdev^2

# Calculate Tracy-Widom statistic for each PC
n <- nrow(features)  # Number of observations (samples)
tracy_widom_stats <- eigenvalues / sqrt((n - seq_along(eigenvalues)) * (n - seq_along(eigenvalues) + 1) / 2)

# Print Tracy-Widom statistics
print(tracy_widom_stats)

# Calculate p-values using the Tracy-Widom cumulative distribution function
p_values <- 1 - pt(tracy_widom_stats, n - 1)

# Print p-values
print(p_values)

# Determine the statistically significant PCs
significant_pcs <- which(p_values < 0.0001)

# Retain the first 10 statistically significant PCs
retained_pcs <- significant_pcs[1:min(length(significant_pcs), 10)]

# Get the retained PCs
retained_pc_vectors <- pca_result$rotation[, retained_pcs]
# Print the retained PCs
print("Retained PCs:")
print(retained_pc_vectors)
```


```{r}
# Load necessary library
library(ggplot2)

# Create a data frame with the provided data
data <- data.frame(
  Epoch = rep(1:20, each = 5),
  Total_Datapoint = rep(c(2000, 4000, 6000, 8000, "Full"), times = 20),
  Accuracy = c(54.17, 50.78, 50.69, 48.44, 51.81, 54.17, 50.52, 82.20, 68.66, 56.70, 
               53.39, 48.57, 77.52, 48.35, 71.67, 46.35, 80.73, 83.42, 52.00, 85.03, 
               89.06, 52.08, 83.07, 90.28, 85.53, 66.15, 76.04, 78.21, 86.11, 93.70, 
               83.33, 74.22, 86.46, 88.80, 90.32, 47.40, 77.99, 80.21, 90.54, 93.35, 
               91.15, 55.86, 88.37, 92.27, 93.85, 87.50, 83.98, 89.24, 91.15, 94.66, 
               89.84, 81.38, 90.89, 90.54, 94.46, 76.04, 70.57, 87.67, 74.31, 94.71, 
               80.99, 75.91, 93.32, 90.54, 94.10, 90.36, 81.38, 87.33, 92.62, 92.54, 
               57.81, 88.02, 79.43, 91.15, 93.90, 81.77, 83.46, 92.36, 92.62, 94.10, 
               60.42, 75.78, 91.84, 94.70, 93.60, 75.78, 79.95, 92.45, 95.05, 94.41, 
               87.24, 87.63, 93.32, 93.40, 92.79, 86.72, 78.26, 90.97, 93.06, 94.10),
  Loss = c(0.70, 0.69, 0.68, 0.69, 0.69, 0.69, 0.69, 0.65, 0.72, 0.68,
           0.69, 0.68, 0.51, 0.68, 0.53, 0.69, 0.68, 0.43, 0.38, 0.28,
           0.66, 0.95, 0.55, 0.41, 0.32, 0.64, 0.63, 0.41, 0.27, 0.09,
           0.54, 0.59, 0.41, 0.37, 0.13, 0.46, 0.43, 0.41, 0.35, 0.12,
           0.52, 0.40, 0.32, 0.56, 0.05, 0.61, 0.34, 0.23, 0.19, 0.25,
           0.61, 0.39, 0.24, 0.30, 0.07, 0.53, 0.50, 0.21, 0.19, 0.21,
           0.69, 0.45, 0.21, 0.33, 0.11, 0.34, 0.37, 0.06, 0.13, 0.06,
           0.61, 0.23, 0.52, 0.11, 0.05, 0.56, 0.27, 0.18, 0.15, 0.11,
           0.52, 0.33, 0.09, 0.27, 0.03, 0.51, 0.26, 0.25, 0.45, 0.02,
           0.33, 0.17, 0.20, 0.46, 0.02, 0.40, 0.82, 0.19, 0.23, 0.02)
)

# Plot for Loss
ggplot(data, aes(x = Epoch, y = Loss, color = Total_Datapoint, group = Total_Datapoint)) +
  geom_smooth(method = "loess",se=FALSE) +
  geom_point(alpha = 0.4) +
  labs(title = "Training Loss across Epoch",
       x = "Epoch",
       y = "Loss",
       color = "Simulation-run: Model Trained on") +
  theme(text=element_text(family="Monaco"))

ggplot(data, aes(x = Epoch, y = Accuracy, color = Total_Datapoint, group = Total_Datapoint)) +
  geom_smooth(method = "loess",se=FALSE) +
  geom_point(alpha = 0.4) +
  labs(title = "Training Accuracy across Epoch",
       x = "Epoch",
       y = "Accuracy",
       color = "Simulation-run: Model Trained on") +
  theme(text=element_text(family="Monaco"))

anova_model <- aov(Loss ~ Total_Datapoint, data = data)

# Check ANOVA table
summary(anova_model)

anova_model1 <- aov(Loss ~ Total_Datapoint, data = data)
summary(anova_model1)

tukey_result <- TukeyHSD(anova_model1)
# Print the Tukey's HSD test results
print(tukey_result)

levene_result <- leveneTest(Accuracy ~ Total_Datapoint, data = data)

# Print the test result
print(levene_result)

# Calculate variance for each group

# Subset the data
larger_sizes <- subset(data, Total_Datapoint %in% c(6000, 8000, "Full"))
smaller_sizes <- subset(data, Total_Datapoint %in% c(2000, 4000))

# Perform one-tailed t-test
t_test_result <- wilcox.test(larger_sizes$Accuracy, smaller_sizes$Accuracy, alternative = "greater")

# Print the result
print(t_test_result)


# Load required library
library(ggplot2)

# Create histograms for each group
ggplot(data, aes(x = Accuracy)) +
  geom_histogram(binwidth = 2, fill = "skyblue", color = "black") +
  facet_wrap(~Total_Datapoint, scales = "free") +
  labs(title = "Histogram of Accuracy by Dataset Size", x = "Accuracy in %", y = "Frequency")

# Create Q-Q plots for each group
ggplot(data, aes(sample = Accuracy)) +
  geom_qq() +
  geom_qq_line() +
  facet_wrap(~Total_Datapoint, scales = "free") +
  labs(title = "Q-Q Plot of Accuracy by Dataset Size")

# Perform Shapiro-Wilk test for normality
shapiro_test <- shapiro.test(smaller_sizes$Accuracy)
shapiro_test
tukey_result
```


```{r}
variances <- tapply(data$Accuracy, data$Total_Datapoint, var)

# Find the group with the lowest variance
group_with_lowest_variance <- names(variances)[which.min(variances)]

# Print the group with the lowest variance and its corresponding variance value
cat("Group with the lowest variance:", group_with_lowest_variance, "\n")
cat("Variance:", variances[group_with_lowest_variance], "\n")

```



```{r}
# Load required libraries
library(ggplot2)
library(tidyr)

# Your provided accuracy values
accuracy_values <- c(
  98.39, 98.49, 98.49, 98.54, 98.29, 98.34, 98.39, 98.34, 98.74, 98.39,
  98.54, 97.73, 98.19, 98.29, 98.29, 98.44, 98.39, 98.54, 98.39, 98.19,
  98.59, 97.93, 98.44, 98.19, 98.49, 98.54, 98.24, 98.59, 98.59, 98.69,
  98.69, 98.64, 98.74, 98.69, 98.49, 98.44, 98.54, 98.74, 98.59, 98.64,
  97.73, 98.49, 98.08, 98.29, 98.14, 98.59, 98.39, 98.59, 98.34, 98.54,
  98.49, 98.59, 98.54, 98.49, 98.64, 98.44, 98.49, 98.34, 98.49, 98.54,
  98.44, 98.54, 98.64, 98.44, 98.54, 98.69, 98.54, 98.54, 98.54, 98.49,
  98.59, 98.69, 98.59, 98.69, 98.59, 98.54, 98.74, 98.69, 98.54, 98.39
)

# Your provided loss values
loss_values <- c(
  0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.01, 0.00,
  0.00, 0.01, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00,
  0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.00, 0.00,
  0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00,
  0.10, 0.07, 0.05, 0.05, 0.03, 0.02, 0.01, 0.01, 0.01, 0.00,
  0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,
  0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.01, 0.01,
  0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.03
)

# Create a dataframe for your data
data <- data.frame(
  Epoch = rep(1:20, 4),
  Kernel = rep(c("3*3", "5*5", "7*7", "9*9"), each = 20),
  Accuracy = accuracy_values,
  Loss = loss_values
)

ggplot(data, aes(x = Epoch, y = Loss, color = Kernel, group = Kernel)) +
  geom_smooth(method = "loess",se=FALSE) +
  geom_point(alpha = 0.4) +
  labs(title = "Training Loss across Epoch",
       x = "Epoch",
       y = "Loss",
       color = "Kernel Size") +
  theme(text=element_text(family="Monaco"))

ggplot(data, aes(x = Epoch, y = Accuracy, color = Kernel, group = Kernel)) +
  geom_smooth(method = "loess",se=FALSE) +
  geom_point(alpha = 0.4) +
  ylim(90,100)+
  labs(title = "Training Accuracy across Epoch",
       x = "Epoch",
       y = "Accuracy",
       color = "Kernel Size") +
  theme(text=element_text(family="Monaco"))


```
```{r}
# Read the matrix from the text file
data <- read.table("/Users/vicegill/Downloads/matrix_0.2.txt", header = FALSE)  # Adjust the file path as needed

# Convert the data frame to a matrix
matrix <- as.matrix(data)

# Display the matrix as an image
heatmap(matrix)
```
```{r}
confusion_matrix <- matrix(data = c(961,48,68,907), nrow = 2, byrow = TRUE)
confusion_matrix
colnames(confusion_matrix) <- rownames(confusion_matrix) <- c("Bottleneck", "Selection")

# Convert the matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(confusion_matrix))
names(conf_df) <- c("Actual", "Predicted", "Count")

# Plot the confusion matrix
ggplot(conf_df, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = Count), color ="white") +
  geom_text(aes(label = Count),color = "black") +
  scale_fill_gradient(low = "lightsalmon", high = "yellowgreen") +
  labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5,face = "bold"))+
  theme(axis.text = element_text(size = 10), 
        axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        text = element_text(family = "Monaco"))

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)
accuracy
precision
recall
f1_score
```
```{r}
# Create a data frame with the results
data <- data.frame(
  Comparison = rownames(tukey_result$Total_Datapoint),
  p_value = tukey_result$Total_Datapoint[,"p adj"]
)

# Extract the comparison categories
comparison <- strsplit(data$Comparison, "-")

# Create a matrix to store p-values
p_matrix <- matrix(NA, nrow = 5, ncol = 5)

# Fill the matrix with p-values
for (i in 1:nrow(data)) {
  row_index <- match(comparison[[i]][2], c("2000", "4000", "6000", "8000", "Full"))
  col_index <- match(comparison[[i]][1], c("2000", "4000", "6000", "8000", "Full"))
  p_matrix[row_index, col_index] <- data$p_value[i]
}

# Plot
library(ggplot2)
library(reshape2)

# Melt the matrix
melted_p <- melt(p_matrix)
melted_p$Var1 <- as.factor(melted_p$Var1)
melted_p$Var2 <- as.factor(melted_p$Var2)
melted_p

# Plot
# Plot
upper_triangular <- melted_p[melted_p$Var1 <= melted_p$Var2, ]
upper_triangular$Var1 <- as.factor(upper_triangular$Var1)
upper_triangular$Var2 <- as.factor(upper_triangular$Var2)
melted_p <- drop_na(melted_p)
ggplot(upper_triangular, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient() +
  theme_minimal() +
  xlab(label = "Training Size")+
  ylab(label = "Training Size")+
  geom_text(aes(label = round(value, 2)), color = "red3", size = 3, vjust = 0.5,family="Monaco") +
  scale_fill_continuous(type = "viridis", name = "Adjusted P-value")+
  geom_tile(data = subset(upper_triangular, Var1 == Var2), fill = "lightgrey") +
  scale_x_discrete(labels = c("2000", "4000", "6000", "8000","Full")) + # Custom x-axis labels
  scale_y_discrete(labels = c("2000", "4000", "6000", "8000", "Full")) + # Custom y-axis labels
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text = element_text(size = rel(0.8)),  # Adjust axis text size
        axis.title = element_text(size = rel(0.8)),
        text = element_text(family = "Monaco"),
        panel.grid = element_blank()) # Adjust axis title size


tukey_result$Total_Datapoint$diff

str(tukey_result$Total_Datapoint)

```
```{r}
confusion_matrix <- matrix(data = c(987,23,19,955), nrow = 2, byrow = TRUE)
confusion_matrix
colnames(confusion_matrix) <- rownames(confusion_matrix) <- c("Bottleneck", "Selection")

# Convert the matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(confusion_matrix))
names(conf_df) <- c("Actual", "Predicted", "Count")

# Plot the confusion matrix
ggplot(conf_df, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = Count), color ="white") +
  geom_text(aes(label = Count),color = "black") +
  scale_fill_gradient(low = "lightsalmon", high = "yellowgreen") +
  labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5,face = "bold"))+
  theme(axis.text = element_text(size = 10), 
        axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        text = element_text(family = "Monaco"))

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)
accuracy
precision
recall
f1_score
```
```{r}
# Load required library
library(ggplot2)

# Create a data frame with the provided data
data <- data.frame(
  Epoch = rep(1:20, times = 4),
  Kernel_Shape = rep(c("9*9", "7*7", "9*15", "15*9"), each = 20),
  Accuracy = c(82.06, 50.86, 50.81, 49.09, 49.04, 48.99, 49.04, 48.99, 49.14, 48.94, 
               49.09, 48.99, 49.19, 49.14, 49.04, 49.09, 48.99, 49.29, 48.99, 48.99,
               48.99, 49.19, 49.14, 49.19, 48.94, 48.99, 49.04, 49.19, 49.04, 48.99, 
               48.94, 49.09, 48.99, 49.14, 49.14, 48.94, 49.04, 49.04, 48.99, 49.19,
               85.38, 96.47, 94.66, 97.58, 97.58, 96.37, 97.93, 97.78, 97.53, 97.93,
               97.93, 97.63, 97.88, 97.88, 97.88, 97.58, 97.98, 97.33, 96.77, 97.83,
               97.33, 97.73, 97.68, 96.67, 97.08, 90.68, 97.83, 96.77, 97.73, 97.88,
               97.63, 97.38, 97.88, 97.88, 97.78, 97.88, 97.98, 97.18, 97.93, 97.88),
  Loss = c(0.67, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69,
           0.69, 0.69, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69,
           0.67, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69,
           0.69, 0.69, 0.70, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69, 0.69,
           0.62, 0.42, 0.36, 0.46, 0.24, 0.36, 0.40, 0.34, 0.32, 0.28,
           0.41, 0.24, 0.21, 0.35, 0.34, 0.30, 0.47, 0.35, 0.14, 0.43,
           0.38, 0.10, 0.24, 0.07, 0.27, 0.05, 0.04, 0.03, 0.04, 0.03,
           0.03, 0.04, 0.21, 0.06, 0.14, 0.02, 0.39, 0.28, 0.03, 0.10)
)

# Convert Accuracy from percentage to fraction
data$Accuracy <- data$Accuracy / 100

# Plot
ggplot(data, aes(x = Epoch, y = Accuracy, color = Kernel_Shape, group = Kernel_Shape)) +
  geom_smooth(method = "loess", se = FALSE,position = position_dodge(0.5)) +
  geom_point(alpha = 0.4)+
  labs(title = "Accuracy across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Accuracy",
       color = "Kernel Shape")+
  theme(text = element_text(family = "Monaco"))
# Plot
ggplot(data, aes(x = Epoch, y = Loss, color = Kernel_Shape, group = Kernel_Shape)) +
  geom_smooth(method = "loess", se = FALSE,position = position_dodge(2))+
  geom_point(alpha = 0.4)+
  labs(title = "Loss across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Loss",
       color = "Kernel Shape")+
  theme(text= element_text(family="Monaco"))
  

```
```{r}
# Load required libraries
library(ggplot2)
library(scales)

# Plot accuracy with confidence intervals
accuracy_plot <- ggplot(data, aes(x = Epoch, y = Accuracy, color = Kernel_Shape, group = Kernel_Shape)) +
  geom_smooth(method = "loess", se = TRUE, position = position_dodge(0.5), alpha = 0.2, size = 1.2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Accuracy Across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Accuracy",
       color = "Kernel Shape") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"),
        legend.position = "top") +
  scale_y_continuous(labels = percent_format())  # Format y-axis as percentage

# Plot loss with confidence intervals
loss_plot <- ggplot(data, aes(x = Epoch, y = Loss, color = Kernel_Shape, group = Kernel_Shape)) +
  geom_smooth(method = "loess", se = TRUE, position = position_dodge(0.5), alpha = 0.2, size = 1.2) +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Loss Across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Loss",
       color = "Kernel Shape") +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white"),
        legend.position = "top")

loss_plot
```
```{r}
square_accuracy <- c(82.06, 50.86, 50.81, 49.09, 49.04, 48.99, 49.04, 48.99, 49.14, 48.94, 
                     49.09, 48.99, 49.19, 49.14, 49.04, 49.09, 48.99, 49.29, 48.99, 48.99,
                     48.99, 49.19, 49.14, 49.19, 48.94, 48.99, 49.04, 49.19, 49.04, 48.99, 
                     48.94, 49.09, 48.99, 49.14, 49.14, 48.94, 49.04, 49.04, 48.99, 49.19)
rectangular_accuracy <- c(85.38, 96.47, 94.66, 97.58, 97.58, 96.37, 97.93, 97.78, 97.53, 97.93,
                          97.93, 97.63, 97.88, 97.88, 97.88, 97.58, 97.98, 97.33, 96.77, 97.83,
                          97.33, 97.73, 97.68, 96.67, 97.08, 90.68, 97.83, 96.77, 97.73, 97.88,
                          97.63, 97.38, 97.88, 97.88, 97.78, 97.88, 97.98, 97.18, 97.93, 97.88)

wilcox.test(rectangular_accuracy,square_accuracy,alternative = c("greater"))
```
```{r}
confusion_matrix <- matrix(data = c(977,34,18,955), nrow = 2, byrow = TRUE)
confusion_matrix
colnames(confusion_matrix) <- rownames(confusion_matrix) <- c("Bottleneck", "Selection")

# Convert the matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(confusion_matrix))
names(conf_df) <- c("Actual", "Predicted", "Count")

# Plot the confusion matrix
ggplot(conf_df, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = Count), color ="white") +
  geom_text(aes(label = Count),color = "black") +
  scale_fill_gradient(low = "lightsalmon", high = "yellowgreen") +
  labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5,face = "bold"))+
  theme(axis.text = element_text(size = 10), 
        axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        text = element_text(family = "Monaco"))

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)
accuracy
precision
recall
f1_score

```
```{r}
# Accuracy and Loss values for each kernel shape
accuracy_3x3 <- c(0.9839, 0.9849, 0.9849, 0.9854, 0.9829, 0.9834, 0.9839, 0.9834, 0.9874, 0.9839, 
                  0.9854, 0.9773, 0.9819, 0.9829, 0.9829, 0.9844, 0.9839, 0.9854, 0.9839, 0.9819)

loss_3x3 <- c(0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.01, 0.00, 
              0.00, 0.01, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00)

accuracy_5x5 <- c(0.9859, 0.9793, 0.9844, 0.9819, 0.9849, 0.9854, 0.9824, 0.9859, 0.9859, 0.9869, 
                  0.9869, 0.9864, 0.9874, 0.9869, 0.9849, 0.9844, 0.9854, 0.9874, 98.59, 0.9864)

loss_5x5 <- c(0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.00, 0.00, 
              0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.00, 0.01, 0.00)

accuracy_7x7 <- c(0.9773, 0.9849, 0.9808, 0.9829, 0.9814, 0.9859, 0.9839, 0.9859, 0.9834, 0.9854, 
                  0.9849, 0.9859, 0.9854, 0.9849, 0.9864, 0.9844, 0.9849, 0.9834, 0.9849, 0.9854)

loss_7x7 <- c(0.10, 0.07, 0.05, 0.05, 0.03, 0.02, 0.01, 0.01, 0.01, 0.00, 
              0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00)

accuracy_9x9 <- c(0.9844, 0.9854, 0.9864, 0.9844, 0.9854, 0.9869, 0.9854, 0.9854, 0.9854, 0.9849, 
                  0.9859, 0.9869, 0.9859, 0.9869, 0.9859, 0.9854, 0.9874, 0.9869, 0.9854, 0.9839)

loss_9x9 <- c(0.10, 0.07, 0.05, 0.04, 0.03, 0.02, 0.01, 0.01, 0.01, 0.01, 
              0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.03)

# Create a data frame
df <- data.frame(
  Kernel_Size = rep(c("3x3", "5x5", "7x7", "9x9"), each = 20),
  Epoch = rep(1:20, times = 4),
  Accuracy = c(accuracy_3x3, accuracy_5x5, accuracy_7x7, accuracy_9x9),
  Loss = c(loss_3x3, loss_5x5, loss_7x7, loss_9x9))

# Print the data frame

ggplot(df, aes(x = Epoch, y = Accuracy, color = Kernel_Size, group = Kernel_Size)) +
  geom_smooth(method = "loess", se = FALSE,position = position_dodge(0.5)) +
  geom_point(alpha = 0.4)+
  labs(title = "Accuracy across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Accuracy",
       color = "Kernel Shape")+
  theme(text = element_text(family = "Monaco"))+
  ylim(c(0.95,1))


ggplot(df, aes(x = Epoch, y = Loss, color = Kernel_Size, group = Kernel_Size)) +
  geom_smooth(method = "loess", se = FALSE,position = position_dodge(2))+
  geom_point(alpha = 0.4)+
  labs(title = "Loss across Epochs for Different Kernel Shapes",
       x = "Epoch",
       y = "Loss",
       color = "Kernel Shape")+
  theme(text= element_text(family="Monaco"))
```
```{r}
# Perform ANOVA for Accuracy
accuracy_anova <- aov( Accuracy~ Kernel_Shape, data = data)

# Print ANOVA summary
summary(accuracy_anova)

tukey_result <- TukeyHSD(accuracy_anova)
tukey_result
# Create a data frame with the results
data <- data.frame(
  Comparison = rownames(tukey_result$Kernel_Shape),
  p_value = tukey_result$Kernel_Shape[,"p adj"]
)
data
# Extract the comparison categories
comparison <- strsplit(data$Comparison, "-")
comparison
# Create a matrix to store p-values
p_matrix <- matrix(NA, nrow = 4, ncol = 4)
data
# Fill the matrix with p-values
for (i in 1:nrow(data)) {
  row_index <- match(comparison[[i]][2], c("7*7", "9*9", "9*15", "15*9"))
  col_index <- match(comparison[[i]][1], c("7*7", "9*9", "9*15", "15*9"))
  p_matrix[row_index, col_index] <- data$p_value[i]
}
p_matrix
accuracy_anova
# Plot
library(ggplot2)
library(reshape2)

# Melt the matrix
melted_p <- melt(p_matrix)


upper_triangular <- melted_p[melted_p$Var2 <= melted_p$Var1, ]
upper_triangular
upper_triangular$Var1 <- as.numeric(upper_triangular$Var1)
upper_triangular$Var2 <- as.numeric(upper_triangular$Var2)

upper_triangular <- drop_na(upper_triangular)
# Create the heatmap plot
ggplot(upper_triangular, aes(x = Var2, y = Var1, fill = value)) +
  geom_tile() +  # Add the heatmap tiles
  scale_fill_gradient() +  # Add gradient color scale
  theme_minimal() +  # Apply a minimal theme
  xlab(label = "Kernel Size") +  # Set x-axis label
  ylab(label = "Kernel Size") +  # Set y-axis label
  geom_text(aes(label = round(value, 2)), color = "red", size = 4, vjust = 0.5, family = "Monaco") +  # Add text labels
  scale_fill_continuous(type = "viridis", name = "Adjusted P-value") +  # Set color scale
  geom_tile(data = subset(upper_triangular, Var1 == Var2)) +  # Add diagonal tiles
  scale_x_discrete(labels = c("15*9", "9*15", "7*7", "9*9")) +  # Customize x-axis labels
  scale_y_discrete(labels = c("15*9", "9*15", "7*7", "9*9")) + 
  geom_tile(data = subset(upper_triangular, Var1 == Var2), fill = "lightgrey") +# Customize y-axis labels
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    axis.text = element_text(size = rel(1)),  # Adjust axis text size
    axis.title = element_text(size = rel(1)),  # Adjust axis title size
    text = element_text(family = "Monaco"),  # Set font family
    panel.grid = element_blank()  # Remove grid lines
  )




unique(unlist(comparison))
```


```{r}
loss_anova <- aov(Loss ~ Kernel_Size, data = df)

# Print ANOVA summary
summary(loss_anova)

tukey_result <- TukeyHSD(loss_anova)

data <- data.frame(
  Comparison = rownames(tukey_result$Kernel_Size),
  p_value = tukey_result$Kernel_Size[,"p adj"]
)


# Extract the comparison categories
comparison <- strsplit(data$Comparison, "-")
comparison <- unique(comparison)
# Create a matrix to store p-values
p_matrix <- matrix(NA, nrow = 4, ncol = 4)

# Fill the matrix with p-values
for (i in 1:nrow(data)) {
  row_index <- match(comparison[[i]][2], c("3x3", "5x5", "7x7", "9x9"))
  col_index <- match(comparison[[i]][1], c("3x3", "5x5", "7x7", "9x9"))
  p_matrix[row_index, col_index] <- data$p_value[i]
}

tukey_result
# Plot
library(ggplot2)
library(reshape2)

# Melt the matrix
melted_p <- melt(p_matrix)


upper_triangular <- melted_p[melted_p$Var1 <= melted_p$Var2, ]

upper_triangular$Var1 <- as.factor(upper_triangular$Var1)
upper_triangular$Var2 <- as.factor(upper_triangular$Var2)

# Remove NA values

# Create the heatmap plot
ggplot(upper_triangular, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +  # Add the heatmap tiles
  scale_fill_gradient() +  # Add gradient color scale
  theme_minimal() +  # Apply a minimal theme
  xlab(label = "Kernel Size") +  # Set x-axis label
  ylab(label = "Kernel Size") +  # Set y-axis label
  geom_text(aes(label = round(value, 2)), color = "white", size = 4, vjust = 0.5, family = "Monaco") +  # Add text labels
  scale_fill_continuous( name = "Adjusted P-value") +  # Set color scale
  geom_tile(data = subset(upper_triangular, Var1 == Var2)) +  # Add diagonal tiles
  scale_x_discrete(labels = c("3*3", "5*5", "7*7", "9*9")) +  # Customize x-axis labels
  scale_y_discrete(labels = c("3*3", "5*5", "7*7", "9*9")) + 
  geom_tile(data = subset(upper_triangular, Var1 == Var2), fill = "lightgrey") +# Customize y-axis labels
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    axis.text = element_text(size = rel(1)),  # Adjust axis text size
    axis.title = element_text(size = rel(1)),  # Adjust axis title size
    text = element_text(family = "Monaco"),  # Set font family
    panel.grid = element_blank()  # Remove grid lines
  )

kruskal.test(Loss ~ Kernel_Size, data = df)
```
```{r}
confusion_matrix <- matrix(data = c(979,13,9,983), nrow = 2, byrow = TRUE)
confusion_matrix
colnames(confusion_matrix) <- rownames(confusion_matrix) <- c("Bottleneck", "Selection")

# Convert the matrix to a data frame for ggplot
conf_df <- as.data.frame(as.table(confusion_matrix))
names(conf_df) <- c("Actual", "Predicted", "Count")

# Plot the confusion matrix
ggplot(conf_df, aes(x = Actual, y = Predicted)) +
  geom_tile(aes(fill = Count), color ="white") +
  geom_text(aes(label = Count),color = "black",size = 6,family="Monaco") +
  scale_fill_gradient(low = "lightsalmon", high = "yellowgreen") +
  labs(x = "Actual", y = "Predicted", title = "Confusion Matrix") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5,face = "bold"))+
  theme(axis.text = element_text(size = 10), 
        axis.title = element_text(size = 14, face = "bold"),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
        text = element_text(family = "Monaco"))

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * precision * recall / (precision + recall)
accuracy
precision
recall
f1_score
```



```{r}
accuracy_<- c(87.50,83.98,89.24,91.15,94.66,
                  80.99,75.91,93.32,90.54,94.10,
                  57.81,88.02,79.43,91.15,93.90,
                  60.42,75.78,91.84,94.70,93.60,
                  86.72,78.26,90.97,93.06,94.10,
                  75.78,79.95,92.45,95.05,94.41 )
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(80,100)

anova(lm(run ~ accuracy))

accuracy_4000 <- c(80.99,75.91,93.32,90.54,94.10)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))

accuracy_6000 <- c(57.81,88.02,79.43,91.15,93.90)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))

accuracy_8000 <- c(60.42,75.78,91.84,94.70,93.60)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))

accuracy_full <- c(86.72,78.26,90.97,93.06,94.10)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))

accuracy <- c(86.72,78.26,90.97,93.06,94.10)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))


accuracy <- c(75.78,79.95,92.45,95.05,94.41)
run <- c(1,2,3,4,5)
data_frame <- data_frame(accuracy, run)
ggplot(aes(x= run, y = accuracy),data=data_frame)+
  geom_point()+
  ylim(70,100)

anova(lm(run ~ accuracy))
```

```{r}
# Install and load necessary packages
library(ggplot2)

# Define the data
epoch <- c('8','10', '13', '16', '18', '20')
data_size <- c(2000, 4000, 6000, 8000, 10000)
accuracy <- matrix(
  c(47.40, 74.22, 86.46, 88.80, 90.32,
    87.50, 80.99, 81.77, 75.78, 86.72,
    83.98, 75.91, 83.46, 79.95, 78.26,
    89.24, 93.32, 92.36, 92.94, 90.97,
    91.15, 90.54, 92.62, 95.05, 93.06,
    94.66, 94.10, 94.10, 94.41, 94.10),
  nrow = 5,
  byrow = TRUE
)
data
# Create a data frame
data <- data.frame(
  epoch = rep(epoch, 5),
  accuracy = c(accuracy),
  data_size = rep(data_size, each = 6)
)

# Plot
ggplot(data, aes(x = epoch, y = accuracy, color = as.factor(data_size), group = data_size)) +
  geom_smooth(method = "loess") +
  labs(x = "Epoch", y = "Accuracy (%)", title = "Accuracy vs. Epoch for Different Data Sizes") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_color_brewer(palette = "Set1")  # You can change the color palette if desired


models <- list()
for (i in 1:length(epoch)) {
  model <- lm(accuracy[i,] ~ data_size)
  models[[i]] <- model
}

# Summary of the models
for (i in 1:length(epoch)) {
  cat("Summary for epoch", epoch[i], ":\n")
  print(summary(models[[i]]))
  cat("\n")
}

p_values <- numeric()
for (i in 1:length(epoch)) {
  model <- lm(accuracy[i,] ~ data_size)
  p_values[i] <- summary(model)$coefficients[2, 4]  # Extract p-value for data_size
}

# Combine epochs and p-values into a data frame
results <- data.frame(epoch = epoch, p_value = p_values)
print(results)

df = data_frame(accuracy=c(47.40,74.22,86.46,88.80,90.32 ),
                training_size = c(2000,4000,6000,8000,9970))
lm(accuracy~training_size, data = df)
anova(lm(accuracy~training_size, data = df))
ggplot(data = df, aes(x = training_size,y = accuracy))+
  geom_smooth(method = "loess",color = "black")+
  geom_point(color="salmon")+
  xlab(label = "Training size")+
  ylab(label = "Accuracy in Percentage %")+
  theme(text = element_text(family = "Monaco"))
```
```{r}
# Define the data
Model <- c("CNN (Image)", "CNN (SNP Matrix)", "CNN (Windowed SFS)", "Multimodal CNN", "SVM (Summary Statistics)", "SVM (PC1 and PC2)")
misclassified_bottleneck <- c(34/(977+34), 23/(987+23), 18/(18+963), 23/(955+23), 13/(979+13), 18/(18+974))
misclassified_selection <- c(18/(955+18), 19/(955+19), 9/(9+994), 10/(996+10), 9/(983+9), 13/(979+13))  # Assuming you have a typo, there's no value for "SVM pc1 and pc2" in this column
misclassified_bottleneck <- round(misclassified_bottleneck*1000)
misclassified_selection <- round(misclassified_selection*1000)

# Create a data frame
data <- data.frame(Model, misclassified_bottleneck, misclassified_selection)
misclassified_bottleneck
# Melt the data frame for ggplot
library(reshape2)
data_melted <- melt(data, id.vars = "Model")


custom_shapes <- c(21, 22, 23, 24, 25, 4)

# Plot the scatter plot with custom shapes
ggplot(data, aes(x = misclassified_bottleneck, y = misclassified_selection, shape = Model,fill = Model)) +
  geom_point(size = 3) +
  scale_shape_manual(values = custom_shapes) + 
  geom_text(aes(label = paste("(", misclassified_bottleneck, ",", misclassified_selection, ")")), vjust = 1, hjust = -0.2,size=2,bold =TRUE, family = "Monaco") +
  xlim(c(13,40))+
  labs(x = "Misclassified Bottleneck", y = "Misclassified Selection", title = "Misclassified Cases by Model")+
  theme(text= element_text(family = "monaco"))
  
```
```{r}
create_upper_triangular_plot <- function(tukey_result, factor_name) {
  # Extract the data from Tukey results and melt
  library(reshape2)
  
  data1 <- data.frame(
  Comparison = rownames(tukey_result$Total_Datapoint),
  p_value = tukey_result$Total_Datapoint[,"p adj"]
)
  print(data1)
  # Convert Comparison to character if it's not
  if (!is.character(data1$Comparison)) {
    data1$Comparison <- as.character(data1$Comparison)
  }
  print(data1)
  comparison <- strsplit(data1$Comparison, "-")
  print(comparison)
  p_matrix <- matrix(NA, nrow = 5, ncol = 5)
  
  for (i in 1:nrow(data1)) {
  row_index <- match(comparison[[i]][2], c("2000", "4000", "6000", "8000","Full"))
  col_index <- match(comparison[[i]][1], c("2000", "4000", "6000", "8000","Full"))
  p_matrix[row_index, col_index] <- data1$p_value[i]
}
  print(p_matrix)
  # Melt the matrix
  melted_p <- melt(p_matrix)
  
 upper_triangular <- melted_p[melted_p$Var1 <= melted_p$Var2, ]
upper_triangular$Var1 <- as.factor(upper_triangular$Var1)
upper_triangular$Var2 <- as.factor(upper_triangular$Var2)

print(upper_triangular)

# Plot
ggplot(upper_triangular, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +  # Add the heatmap tiles
  scale_fill_gradient() +
  geom_text(aes(label = round(value, 2)), color = "red", size = 4, vjust = 0.5, family = "Monaco") +  # Add text labels
  scale_fill_continuous(type = "viridis", name = "Adjusted P-value") +  # Add gradient color scale
  theme_minimal() +  # Apply a minimal theme
  scale_x_discrete(labels = c("2000", "4000", "6000", "8000", "Full")) +  # Customize x-axis labels
  scale_y_discrete(labels = c("2000", "4000", "6000", "8000", "Full")) +  # Customize y-axis labels
  geom_tile(data = subset(upper_triangular, Var1 == Var2), fill = "lightgrey") +  # Add off-diagonal tiles
  xlab("Number of Simulations") +  # Set x-axis label
  ylab("Number of Simulations") +  # Set y-axis label
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    axis.text = element_text(size = rel(1)),  # Adjust axis text size
    axis.title = element_text(size = rel(1)),  # Adjust axis title size
    text = element_text(family = "Monaco"),  # Set font family
    panel.grid = element_blank()  # Remove grid lines
  ) 
}
# Example usage
create_upper_triangular_plot(tukey_result = tukey_result, factor_name = "Total_Datapoint")
ggplot(upper_triangular, aes(x = Var2, y = Var1, fill = value)) +
  geom_tile() +  # Add the heatmap tiles
  scale_fill_gradient() +  # Add gradient color scale
  theme_minimal() +  # Apply a minimal theme
  xlab(label = "Kernel Size") +  # Set x-axis label
  ylab(label = "Kernel Size") +  # Set y-axis label
  geom_text(aes(label = round(value, 2)), color = "red", size = 4, vjust = 0.5, family = "Monaco") +  # Add text labels
  scale_fill_continuous(type = "viridis", name = "Adjusted P-value") +  # Set color scale
  geom_tile(data = subset(upper_triangular, Var1 == Var2)) +  # Add diagonal tiles
  scale_x_discrete(labels = c("15*9", "9*15", "7*7", "9*9")) +  # Customize x-axis labels
  scale_y_discrete(labels = c("15*9", "9*15", "7*7", "9*9")) + 
  geom_tile(data = subset(upper_triangular, Var1 == Var2), fill = "lightgrey") +# Customize y-axis labels
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
    axis.text = element_text(size = rel(1)),  # Adjust axis text size
    axis.title = element_text(size = rel(1)),  # Adjust axis title size
    text = element_text(family = "Monaco"),  # Set font family
    panel.grid = element_blank()  # Remove grid lines
  )
tukey_result
```

