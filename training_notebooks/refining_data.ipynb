{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset , DataLoader , random_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GeneticDataset(Dataset):\n",
    "    def __init__(self,root_folder, transform =None):\n",
    "        self.root_folder = root_folder\n",
    "        self.transform = transform\n",
    "        self.class_labels = sorted(os.listdir(root_folder))\n",
    "        self.class_to_idx = {label: idx for idx ,label in enumerate(self.class_labels)}\n",
    "        self.file_list = self._build_file_list()\n",
    "    \n",
    "    def _build_file_list(self):\n",
    "        file_list = []\n",
    "        for class_label in self.class_labels:\n",
    "            class_path = os.path.join(self.root_folder,class_label)\n",
    "            class_image = [os.path.join(class_path,image_path) for image_path in os.listdir(class_path)]\n",
    "            file_list.extend(class_image)\n",
    "        return file_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        file_path = self.file_list[index]\n",
    "        image = Image.open(file_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        class_label = os.path.basename(os.path.dirname(file_path))\n",
    "        label = self.class_to_idx[class_label]\n",
    "        if self.root_folder.find(\"training\") != -1:\n",
    "            find = re.match(r\".+?[_].+?[_].+?[_](.+?)[.][p][n][g]\",file_path)\n",
    "        else:\n",
    "            find = re.match(r\".+?[_].+?[_](.+?)[.][p][n][g]\",file_path)\n",
    "        if (self.transform) :\n",
    "            image = self.transform(image)\n",
    "        return {'image': image, 'label': label, \"coefficient\" : float(find[1]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "source_folder = 'data/images'\n",
    "train_folder = 'data/training_data/training_images/selection'\n",
    "test_folder = 'data/test_data/selection'\n",
    "\n",
    "# Create train and test folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get list of all images in source folder\n",
    "all_images = os.listdir(source_folder)\n",
    "\n",
    "# Randomly select 200 images\n",
    "selected_images = random.sample(all_images, 800)\n",
    "\n",
    "# Move selected images to train folder\n",
    "for image in selected_images:\n",
    "    src = os.path.join(source_folder, image)\n",
    "    dst = os.path.join(train_folder, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# Move remaining images to test folder\n",
    "remaining_images = set(all_images) - set(selected_images)\n",
    "for image in remaining_images:\n",
    "    src = os.path.join(source_folder, image)\n",
    "    dst = os.path.join(test_folder, image)\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths\n",
    "source_folder = 'data/data_bottleneck/images'\n",
    "train_folder = 'data/training_data/training_images/bottleneck'\n",
    "test_folder = 'data/test_data/bottleneck'\n",
    "\n",
    "# Create train and test folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Get list of all images in source folder\n",
    "all_images = os.listdir(source_folder)\n",
    "\n",
    "# Randomly select 200 images\n",
    "selected_images = random.sample(all_images, 750)\n",
    "\n",
    "# Move selected images to train folder\n",
    "for image in selected_images:\n",
    "    src = os.path.join(source_folder, image)\n",
    "    dst = os.path.join(train_folder, image)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "# Move remaining images to test folder\n",
    "remaining_images = set(all_images) - set(selected_images)\n",
    "for image in remaining_images:\n",
    "    src = os.path.join(source_folder, image)\n",
    "    dst = os.path.join(test_folder, image)\n",
    "    shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = GeneticDataset(\"data_images\")\n",
    "generator = torch.Generator().manual_seed(46)\n",
    "length_data = len(data)\n",
    "training_size = int(0.8*length_data)\n",
    "testing_size = length_data - training_size\n",
    "\n",
    "train_data , test_data = random_split(data,[training_size, testing_size],generator=generator)\n",
    "print(len(train_data))\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_table(\"data/data/data_table_selection.txt\")\n",
    "data\n",
    "for file in os.listdir(\"data/data/txt_file_selection\"):\n",
    "    file_path = os.path.join(\"data/data/txt_file_selection\",file)\n",
    "    print(file_path)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    start_index = lines.index(\" The allele frequency numbers are :-  \") + 1\n",
    "\n",
    "\n",
    "    end_index = next(i for i, line in enumerate(lines) if line.startswith(\"1. The Tajima'D for the given sequence is\"))\n",
    "\n",
    "    sfs = [num for num in lines[start_index:end_index]]\n",
    "    sfs = \" \".join(sfs)\n",
    "    sfs = sfs[1:len(sfs)-1]\n",
    "    sfs = sfs.split()\n",
    "    sfs = list(map(float, sfs))\n",
    "    category = [0]*9\n",
    "    category[0] = sum(sfs[0:1])\n",
    "    category[1] = sum(sfs[1:2])\n",
    "    category[2] = sum(sfs[2:4])\n",
    "    category[4] = sum(sfs[4:7])\n",
    "    category[5] = sum(sfs[7:10])\n",
    "    category[6] = sum(sfs[10:20])\n",
    "    category[7] = sum(sfs[20:50])\n",
    "    category[8] = sum(sfs[50:])\n",
    "    find = re.match(r\".+?[_].+?[_](.+?)[.][t][x][t]\",file_path)\n",
    "    coef = float(find[1])\n",
    "    for i in category:\n",
    "        print(i)\n",
    "    print(coef)\n",
    "    j=1\n",
    "    for i in category:\n",
    "        data.loc[data[\"selection_coefficient\"]==coef,f\"category_sfs_{j}\"] = i\n",
    "        j+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1 = pd.read_table(\"data/training_data/data_table_bottleneck.txt\")\n",
    "\n",
    "for file in os.listdir(\"data/training_data/txt_file_bottleneck\"):\n",
    "    file_path = os.path.join(\"data/training_data/txt_file_bottleneck\",file)\n",
    "    print(file_path)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    lines = content.split(\"\\n\")\n",
    "\n",
    "    start_index = lines.index(\" The allele frequency numbers are :-  \") + 1\n",
    "\n",
    "\n",
    "    end_index = next(i for i, line in enumerate(lines) if line.startswith(\"1. The Tajima'D for the given sequence is\"))\n",
    "\n",
    "    sfs = [num for num in lines[start_index:end_index]]\n",
    "    sfs = \" \".join(sfs)\n",
    "    sfs = sfs[1:len(sfs)-1]\n",
    "    sfs = sfs.split()\n",
    "    sfs = list(map(float, sfs))\n",
    "    category = [0]*9\n",
    "    category[0] = sum(sfs[0:1])\n",
    "    category[1] = sum(sfs[1:2])\n",
    "    category[2] = sum(sfs[2:4])\n",
    "    category[4] = sum(sfs[4:7])\n",
    "    category[5] = sum(sfs[7:10])\n",
    "    category[6] = sum(sfs[10:20])\n",
    "    category[7] = sum(sfs[20:50])\n",
    "    category[8] = sum(sfs[50:])\n",
    "    find = re.match(r\".+?[_].+?[_].+?[_].+?[_](.+?)[.][t][x][t]\",file_path)\n",
    "    coef = float(find[1])\n",
    "    for i in category:\n",
    "        print(i)\n",
    "    print(coef)\n",
    "    j=1\n",
    "    for i in category:\n",
    "        data1.loc[data1[\"bottleneck_intensity\"]==coef,f\"category_sfs_{j}\"] = i\n",
    "        j+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training , data_testing = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
