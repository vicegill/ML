{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708adf57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:53.600377Z",
     "iopub.status.busy": "2024-04-14T07:41:53.599506Z",
     "iopub.status.idle": "2024-04-14T07:41:55.130751Z",
     "shell.execute_reply": "2024-04-14T07:41:55.131398Z"
    },
    "papermill": {
     "duration": 1.56234,
     "end_time": "2024-04-14T07:41:55.131603",
     "exception": false,
     "start_time": "2024-04-14T07:41:53.569263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaskaran/.conda/envs/training/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader , random_split\n",
    "from torchvision import transforms , datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fe17da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.259815Z",
     "iopub.status.busy": "2024-04-14T07:41:55.258999Z",
     "iopub.status.idle": "2024-04-14T07:41:55.261777Z",
     "shell.execute_reply": "2024-04-14T07:41:55.262436Z"
    },
    "papermill": {
     "duration": 0.118266,
     "end_time": "2024-04-14T07:41:55.262602",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.144336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not availabe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f701e568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.294162Z",
     "iopub.status.busy": "2024-04-14T07:41:55.292866Z",
     "iopub.status.idle": "2024-04-14T07:41:55.296997Z",
     "shell.execute_reply": "2024-04-14T07:41:55.296360Z"
    },
    "papermill": {
     "duration": 0.022742,
     "end_time": "2024-04-14T07:41:55.297147",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.274405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class GeneticDataset(Dataset):\n",
    "    def __init__(self,root_folder, transform =None):\n",
    "        self.root_folder = root_folder\n",
    "        self.transform = transform\n",
    "        self.class_labels = sorted(os.listdir(root_folder))\n",
    "        self.class_to_idx = {label: idx for idx ,label in enumerate(self.class_labels)}\n",
    "        self.file_list = self._build_file_list()\n",
    "    \n",
    "    def _build_file_list(self):\n",
    "        file_list = []\n",
    "        for class_label in self.class_labels:\n",
    "            class_path = os.path.join(self.root_folder,class_label)\n",
    "            class_image = [os.path.join(class_path,image_path) for image_path in os.listdir(class_path)]\n",
    "            file_list.extend(class_image)\n",
    "        return file_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        file_path = self.file_list[index]\n",
    "        image = Image.open(file_path)\n",
    "        image = image.convert(\"RGB\")\n",
    "        resized_image = image.resize((200,200))\n",
    "        class_label = os.path.basename(os.path.dirname(file_path))\n",
    "        label = self.class_to_idx[class_label]\n",
    "        if self.root_folder.find(\"training\") != -1:\n",
    "            find = re.match(r\".+?[_].+?[_].+?[_](.+?)[.][p][n][g]\",file_path)\n",
    "        else:\n",
    "            find = re.match(r\".+?[_].+?[_](.+?)[.][p][n][g]\",file_path)\n",
    "        if (self.transform) :\n",
    "            resized_image = self.transform(resized_image)\n",
    "        return {'image': resized_image, 'label': label, \"coefficient\" : float(find[1]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f54906a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.327003Z",
     "iopub.status.busy": "2024-04-14T07:41:55.326195Z",
     "iopub.status.idle": "2024-04-14T07:41:55.366232Z",
     "shell.execute_reply": "2024-04-14T07:41:55.366924Z"
    },
    "papermill": {
     "duration": 0.058016,
     "end_time": "2024-04-14T07:41:55.367093",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.309077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "data = GeneticDataset(\"/home/jaskaran/data_images\", transform= transform)\n",
    "generator = torch.Generator().manual_seed(46)\n",
    "length_data = len(data)\n",
    "training_size = int(0.8*length_data)\n",
    "testing_size = length_data - training_size\n",
    "\n",
    "total_samples = 8000\n",
    "\n",
    "\n",
    "\n",
    "indices = np.random.choice(len(data), total_samples, replace=False)\n",
    "\n",
    "# Create a subset of the dataset using the random indices\n",
    "subset_data = torch.utils.data.Subset(data, indices)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data , test_data = random_split(data,[training_size, testing_size],generator=generator)\n",
    "\n",
    "training_dataloader= DataLoader(train_data,batch_size=64,shuffle=True, drop_last=True)\n",
    "testing_dataloader = DataLoader(test_data,batch_size=64,shuffle=True, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885dc937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.396212Z",
     "iopub.status.busy": "2024-04-14T07:41:55.395358Z",
     "iopub.status.idle": "2024-04-14T07:41:55.571551Z",
     "shell.execute_reply": "2024-04-14T07:41:55.570830Z"
    },
    "papermill": {
     "duration": 0.192307,
     "end_time": "2024-04-14T07:41:55.571699",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.379392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9970"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1599][\"image\"].shape\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067a0c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.606848Z",
     "iopub.status.busy": "2024-04-14T07:41:55.606029Z",
     "iopub.status.idle": "2024-04-14T07:41:55.608914Z",
     "shell.execute_reply": "2024-04-14T07:41:55.608256Z"
    },
    "papermill": {
     "duration": 0.024532,
     "end_time": "2024-04-14T07:41:55.609060",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.584528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, \n",
    "                               out_channels=8,\n",
    "                               kernel_size=7, \n",
    "                               stride= 1,\n",
    "                               padding = 7)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size =2,\n",
    "                                    stride=2)\n",
    "        #self.conv2 = nn.Conv2d(in_channels = 8,\n",
    "                               #out_channels = 32,\n",
    "                               #kernel_size = 2,\n",
    "                               #stride = 1,\n",
    "                               #padding = 2)\n",
    "        self.fc1 = nn.Linear(86528,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,2)\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "       x = self.conv1(x)\n",
    "       x = self.relu(x)\n",
    "       x = self.maxpool(x)\n",
    "    \n",
    "       #x = self.conv2(x)\n",
    "       #x = self.relu(x)\n",
    "       #x = self.maxpool(x)\n",
    "    \n",
    "       x = self.flatten(x)\n",
    "    \n",
    "       x = self.fc1(x)\n",
    "       x = self.relu(x)\n",
    "       x = self.dropout(x)\n",
    "    \n",
    "       x = self.fc2(x)\n",
    "       x = self.relu(x)\n",
    "       x = self.dropout(x)\n",
    "    \n",
    "       x = self.fc3(x)\n",
    "    \n",
    "       return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5222e123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T07:41:55.643212Z",
     "iopub.status.busy": "2024-04-14T07:41:55.642404Z",
     "iopub.status.idle": "2024-04-14T12:09:10.782399Z",
     "shell.execute_reply": "2024-04-14T12:09:10.782726Z"
    },
    "papermill": {
     "duration": 16035.160562,
     "end_time": "2024-04-14T12:09:10.782840",
     "exception": false,
     "start_time": "2024-04-14T07:41:55.622278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20,loss : 0.16 Accuracy: 93.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20,loss : 0.22 Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20,loss : 0.25 Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20,loss : 0.19 Accuracy: 95.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20,loss : 0.23 Accuracy: 94.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20,loss : 0.08 Accuracy: 96.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20,loss : 0.06 Accuracy: 95.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20,loss : 0.04 Accuracy: 96.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20,loss : 0.03 Accuracy: 96.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20,loss : 0.17 Accuracy: 94.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20,loss : 0.06 Accuracy: 97.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20,loss : 0.16 Accuracy: 97.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20,loss : 0.12 Accuracy: 97.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20,loss : 0.05 Accuracy: 95.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20,loss : 0.03 Accuracy: 96.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20,loss : 0.06 Accuracy: 97.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20,loss : 0.02 Accuracy: 97.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20,loss : 0.08 Accuracy: 97.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20,loss : 0.01 Accuracy: 95.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20,loss : 0.03 Accuracy: 97.28%\n",
      "Model is trained\n"
     ]
    }
   ],
   "source": [
    "# Set seed for CPU operations\n",
    "torch.manual_seed(45)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set seed for CUDA operations\n",
    "    torch.cuda.manual_seed(45)\n",
    "    torch.cuda.manual_seed_all(45)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.to(\"cuda:3\")\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in training_dataloader:\n",
    "        images = batch['image'].to(\"cuda:3\")\n",
    "        labels = batch['label'].to(\"cuda:3\")  # Ensure labels are also moved to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in testing_dataloader:\n",
    "            images = batch['image'].to(\"cuda:3\")\n",
    "            labels = batch['label'].to(\"cuda:3\")\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    accuracy = correct / total \n",
    "    print(f'Epoch {epoch + 1}/{num_epochs},loss : {loss:.2f} Accuracy: {accuracy:.2%}')\n",
    "\n",
    "print(\"Model is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb70219a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T12:09:10.808065Z",
     "iopub.status.busy": "2024-04-14T12:09:10.807498Z",
     "iopub.status.idle": "2024-04-14T12:09:10.920930Z",
     "shell.execute_reply": "2024-04-14T12:09:10.920549Z"
    },
    "papermill": {
     "duration": 0.127644,
     "end_time": "2024-04-14T12:09:10.921031",
     "exception": false,
     "start_time": "2024-04-14T12:09:10.793387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(model.state_dict())\n",
    "torch.save(model.state_dict(), f'model_state_dict_full_1conv_0.001_7*7_8_filter_images_lr_0.0001.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df92e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[977  34]\n",
      " [ 18 955]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = torch.load(\"/home/jaskaran/model_state_dict_full_1conv_0.001_7*7_8_filter_images_lr_0.0001.pth\")\n",
    "model = CNN()\n",
    "model.load_state_dict(k)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have your CNN model instantiated as 'model'\n",
    "# Assuming you have your testing dataloader prepared as 'testing_dataloader'\n",
    "\n",
    "# Set your model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the testing dataloader and collect predictions and labels\n",
    "with torch.no_grad():\n",
    "    for batch in testing_dataloader:\n",
    "        image = batch['image']\n",
    "        labels = batch['label']\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16039.263509,
   "end_time": "2024-04-14T12:09:11.968691",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/jaskaran/training_notebooks/training.ipynb",
   "output_path": "/home/jaskaran/training_notebooks/training_complete_lr_0.0001.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T07:41:52.705182",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
